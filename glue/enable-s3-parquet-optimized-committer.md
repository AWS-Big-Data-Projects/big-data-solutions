The prime reason and advantage for setting up this property is as follows : 

        Whenever you or one of your applications writes a file to S3, there's a short window of time where the file needs to be propagated throughout the S3 backend system. If you try to access that file within that window of time (as in, immediately after writing it), there's a chance the file has not finished propagating and S3 returns an error.It helps to avoid issue that can occur with Amazon S3 eventual consistency during job and task commit phases, and helps improve job correctness under task failure conditions.

        Glue ETL Jobs run on the Apache Spark framework, which by default writes all output to a temporary directory in S3 and when all executors have finished writing, files are moved from this temporary directory to your selected destination path. S3 does not have the concept of directories (everything is a named prefix), so this move operation is basically just a rename to change the file's prefix. Sometime per my experience and knowledge with the Spark and the GlueETL , the jobs fails while writing the data to s3. The best way to address this is to enable the EMRFS S3-optimized committer [1] which is available in Glue [2] and removes such errors by using an optimized S3 write logic.
